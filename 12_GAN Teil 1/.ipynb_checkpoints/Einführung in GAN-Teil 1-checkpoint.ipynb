{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN - Computer erfinden Menschen - Teil 1\n",
    "Nimm Dir ein bisschen Zeit und schau Dir dieses Bild an:\n",
    "\n",
    "![Abb 1: Frau mit Ohrringen](FrauMitOhringen.PNG)\n",
    "\n",
    "\n",
    "Schau Dir ihr linkes Ohr und die untere rechte Ecke des Bildes ein wenig genauer an. Seltsam oder? Irgendwie stimmt da was nicht. Das liegt daran, dass dieses Bild von einem neuronalen Netz komplett erfunden wurde. Wichtig ist hierbei, dass es wirklich erfunden wurde. Das Netz hat sich also nicht eines \"Gesicht - Baukastens\" bedient, in dem die einzelnen Komponenten eines Gesichts parametrisiert vordefiniert sind. Es wurde aus einem Rauschen erzeugt, das man in die linke Seite des Netzes reingesteckt hat. Faszinierend oder? Wenn Du noch mehr erfundene Gesichter sehen möchtest, kannst du das übrigens unter [https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/) tun.\n",
    "\n",
    "In diesem Blog möchte ich zeigen, wie einfach man sich so ein Netz selbst bauen kann, und dass hinter der ganzen Sache nicht allzu viel Magie steckt. Wenn Du prinzipiell weißt, wie ein neuronales Netz funktioniert, solltest Du mit diesem Blog keine größeren Verständnisprobleme haben. Wenn Du Dein Wissen lieber noch einmal ein wenig auffrischen möchtest, so kann ich dir meine Blogartikel zu dem Thema empfehlen:\n",
    "\n",
    "* [Einstieg in neuronale Netze mit Keras](https://www.mt-ag.com/einstieg-in-neuronale-netze-mit-keras/)\n",
    "* [Einstieg in Convolutional Neuronale Netze mit Keras](https://www.mt-ag.com/einstieg-in-convolutional-neuronale-netze-mit-keras/)\n",
    "* [So entwirft man ein Top CNN](https://www.mt-ag.com/so-entwirft-man-ein-top-cnn/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Was steckt dahinter\n",
    "Die Technik, die selbständig Bilder, Texte und Musik gestalten kann nennt sich GAN. Das steht für __G__enerative __A__dversarial __N__etworks also quasi Kreativität durch sportlichen Ehrgeiz. Im Folgenden werde ich durch die einzelnen Komponenten gehen und den eigentlichen Trick der GANs herausarbeiten. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das G in GAN\n",
    "Was man im Endeffekt haben will, ist ein möglichst einfaches neuronales Netz, dass aus einem mit Zufallszahlen belegten Tensor (ein Rauschen) ein Bild erzeugt, von dem man nicht mehr sagen kann, ob es ein Fake ist oder nicht. Dieses Netz nennt man einen Generator. Wir haben also ein:\n",
    "$$G(z) \\to x$$\n",
    "Dabei ist $z$ das Rauschen und $x$ ein Bild. Wenn wir dieses Netz hätten, könnten wir für heute Feierabend machen und mit unseren Erfolgen prahlen. Dummerweise haben wir dieses Netz aber noch nicht, weil wir das Netz allein nicht trainieren können. Neuronale Netze trainiert man ja, indem man das tatsächliche Ergebnis vom erwarteten abzieht und diese Differenz (den Fehler) über das Gradientenverfahren langsam gegen Null treibt. Man braucht also ein erwartetes Ergebnis fürs Trainieren. Hier haben wir aber kein erwartetes Ergebnis, da das Bild erfunden sein soll. \n",
    "\n",
    "![Abb. 2: Generator]( Generator.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diskriminierung ist nicht immer schlecht\n",
    "Das Wort _diskriminieren_ kommt vom lateinischen _discriminare_ und bedeutet so viel wie _unterscheiden_ und das ist genau, was wir hier brauchen. Wir brauchen ein zweites neuronales Netz, dass in der Lage ist, zu unterscheiden, ob ein Bild _fake_ oder _real_ ist. Dieses Netz nennt man den __Diskriminator__:\n",
    "$$D(x) \\to [0,1]$$\n",
    "Es bekommt also ein Bild $x$ gegeben und soll unterscheiden, ob $x$ ein echtes Bild also __1__ oder ein fake also __0__ ist.\n",
    "Dieses Netz können wir gut trainieren, indem wir ihm einen Stapel richtiger Bilder und einen Stapel vom Generator erstellter Bilder geben. Da kennen wir das erwartete Ergebnis und haben somit alles, was wir brauchen.\n",
    "\n",
    "![Abb. 3: Diskriminator]( Diskriminator.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der gemeinsame Wettstreit macht uns besser\n",
    "Wir haben nun also ein Werkzeug in der Hand, um den Generator zu trainieren, nämlich den Diskriminator. Dadurch wird er immer besser und erzeugt immer realistischere Bilder. Somit fällt es dem Diskriminator immer schwerer zu unterscheiden, ob ein Bild _fake_ oder _real_ ist. Es liegt also auf der Hand den Diskriminator ebenfalls zu trainieren, damit er immer scharfsinniger bei seinem Urteil wird. Beide Netze ziehen sich somit aneinander hoch. \n",
    "Das Training läuft im Pilgerschritt:\n",
    "\n",
    "1. Zuerst generiert man mit dem Generator einen Stapel Fake – Bilder\n",
    "2. Diese Bilder nimmt man zusammen mit gleich vielen echten Bildern, um den Diskriminator zu trainieren. Dadurch wird der Diskriminator ein wenig besser.\n",
    "3. Jetzt verbindet man beide Netze zu einem großen Netz, das ein Rauschen bekommt und sagt, ob das Ergebnis _fake_ oder _real_ ist. $D(G(z)) \\to [0,1]$\n",
    "4. In diesem  Netz friert man die Gewichte des Diskriminators ein, so dass sie nicht trainiert werden können. Wenn also der Fehler über das Gradientenverfahren ausgetrieben wird, wird der Diskriminator nicht verändert.\n",
    "5. Dann trainiert man das ganze Netz mit einem Stapel Rauschens und fordert, dass das Ergebnis immer _real_ sein sollen, da wir ja die Realität fälschen wollen. $\\lim{b \\to 1} D(G(z)) \\to b$\n",
    "6. Nun entfriert man den Diskriminator wieder und beginnt von vorne, bis einen die Ergebnisse überzeugen.\n",
    "\n",
    "![Abb. 4: Training](Training.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Schluss und Ausblick\n",
    "Soviel zur grauen Theorie. Der Gedanke ist einfach und genial, bei der Implementierung mit Keras gibt es noch den einen oder anderen Haken, mit dem man sich befassen muss aber dazu mehr im zweiten Teil. Da werde ich anhand der MNIST Daten, dem Rechner beibringen Ziffern von Hand zu schreiben.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "intro_to_gans.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
